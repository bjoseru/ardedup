#!/Users/bsr047/Documents/Software/ardedup/venv/bin/python3
#
# ARDEDUP - ARchiver and DEDUPlicator
#
# Scan directory trees and extract images (and other fileformats) and
# store them in a unified location, while preserving information about
# the source location. During this preservation stage, exact
# duplicates (same sha1 hash) are removed, even though information
# about all identical copies is preserved. In a secondary stage a
# perceptial difference hash for image file is used to identify images
# that appear to be the same, even though they may have different
# resolutions or have been edited for colour, sharpness, etc. These
# images are then clustered together.
# 
# Copyright (C) 2021 by Björn Rüffer

import dhash                    # for difference hashes
import typer                    # CLI handling
import pathlib
import os
import pretty_errors
# from rich import print
from rich.console import Console
print = Console().print
import hashlib
import collections
import shutil
import imghdr
import tqdm
import colorama
# import sys
# print(sys.version)
from PIL import Image
import os.path
import re
from tinydb import TinyDB, Query
from tinydb.storages import JSONStorage
from tinydb.middlewares import CachingMiddleware
import atexit
from tabulate import tabulate
from typing import List

File = collections.namedtuple('File', [
    'path',
    'sha1',
    'diskname',
    'dev',
    'size',
    'atime',
    'ctime',
    'mtime',
    'imgtype',
    'dhash128',
    'im_mode',
    'im_size',
    ],defaults = [None] * 11)

app = typer.Typer()
db = TinyDB('data.json',
            storage=CachingMiddleware(JSONStorage),
            # sort_keys=True,
            indent=4,
            separators=(',', ': '))
Entry = Query()

def cleanup():
    db.close()
    print('Bye now.')

atexit.register(cleanup)
# atexit.register(db.close)

def get_info(diskname: str, de: os.DirEntry):
    'internal function to produce the information needed about individual files, especially images'
    sha1 = None
    imgtype = None
    dhash128 = None
    im_mode = None
    im_size = None
    if de.is_file():
        try:
            with open(de.path,'rb') as f:
                sha1 = hashlib.sha1(f.read()).hexdigest()
        except PermissionError:
            pass
        except OSError as e:
            # print('Encountered an OSError', e)
            typer.echo()
            typer.echo(typer.style(fr'Cannot SHA1 file: "{de.path}"',bg="red",fg="white"))
            # raise typer.Exit()
        try:    
            imgtype = imghdr.what(de.path)
        except (FileNotFoundError, IsADirectoryError, OSError):
            pass


    if sha1 and imgtype:
        try:
            image = Image.open(de.path)
            row, col = dhash.dhash_row_col(image)
            im_mode = image.mode
            im_size = image.size
            dhash128 = dhash.format_hex(row, col)
            image.close()
        except OSError:
            pass
        
    return File(**{
        'path': pathlib.Path(de.path).absolute().__str__(),
        'size': de.stat().st_size,
        'imgtype': imgtype,
        'dhash128': dhash128,
        'diskname': diskname,
        'dev': de.stat().st_dev,
        'atime': de.stat().st_atime_ns,  # Time of most recent access expressed in nanoseconds as an integer
        'ctime': de.stat().st_ctime_ns,  # Time of most recent content modification expressed in nanoseconds as an integer
        'mtime': de.stat().st_mtime_ns,  # the time of most recent metadata change on Unix / the time of creation on Windows, expressed in nanoseconds as an integer
        'sha1': sha1,
        'im_mode' : im_mode,
        'im_size' : im_size,        
    })

def copy_file(fileinfo: File):
    data = pathlib.Path('./data')
    try:
        os.mkdir(data)
    except FileExistsError:
        pass
    try:
        os.mkdir(data / fileinfo.sha1[:2])
    except FileExistsError:
        pass
    dst = data / fileinfo.sha1[:2] / fileinfo.sha1[2:]
    stat = os.stat(dst)
    if not fileinfo.sha1 and (stat.st_size != fileinfo.size):
        try:
            try:
                shutil.copyfile(fileinfo.path, dst)
            except FileNotFoundError:
                shutil.copyfile(fileinfo.path, dst)
        except OSError as e:
            typer.echo()
            typer.echo(typer.style(f'Cannot copy file: "{de.path}"',bg="red",fg="white"))

def _scan(directories,diskname,filetypes):
    'the actual scanner, needed for recursion'
    for directory in directories:
        directory = pathlib.Path(directory)
        subdirs = list()
        # print(f'Scanning {directory}:')
        with os.scandir(directory) as dir:
            copied = 0
            for entry in tqdm.tqdm(dir, desc = f'{colorama.Style.DIM}{directory.absolute()}{colorama.Style.RESET_ALL}', leave=True, colour='#555500', total=os.stat(directory).st_nlink-2):
                if entry.is_dir():
                    subdirs.append(entry.path)
                    # print(f'add "{entry.path}" to scan list')
                elif re.match(filetypes,
                              os.path.basename(entry.path).split('.')[-1].lower()) and \
                              not db.contains(Entry.name == pathlib.Path(entry.path).absolute().__str__()):
                    # print(f"MATCH: {os.path.basename(entry.path).split('.')[-1].lower()} in {filetypes}.")
                    info = get_info(diskname, entry)
                    if info and info.sha1: # and info.dhash128:
                        copy_file(info)
                        copied += 1
                        try:
                            db.upsert(info._asdict(),
                                      (Entry.path == info.path) & (Entry.sha1 == info.sha1))
                        except ValueError as e:
                            print(f'[bold]encourered ValueError: {e}[/bold]')
                    # else:
                    #     print(f'File {info.path} {info.sha1}.')
                # else:
                #     print(f"File {os.path.basename(entry.path).lower()}:")
                #     print(f"Filetype {os.path.basename(entry.path).split('.')[-1].lower()} not in the list {filetypes}.")
            print(f'Copied {copied} files from "{directory}".')
        if subdirs:
            # print(subdirs)
            scan(list(subdirs), diskname=diskname, filetypes=filetypes)

@app.command()
def scan(
        directories: List[str] = typer.Argument(...,
        help=re.sub("\s\s+" , " ", """Indicates the list of directories to archive and deduplicate. This
        program only makes copies of files in the directories
        (under ./data/), and will not write to the directories
        itself (in particular, files are not moved, but
        copied).
        """)),
        diskname: str = typer.Option("",
            help=re.sub("\s\s+" , " ", """The name of a (possibly external) disk containing the directories to
            be scanned. This is stored along with every file to
            indicate the source disk (e.g., when cataloging a large
            set of external hard drives, which was the motivation for
            this software).""")),
        filetypes: str = typer.Option(r'rgb|gif|pbm|pgm|ppm|tiff?|rast|xbm|jpe?g|bmp|png|webp|exr|docx?|odf|pdf|rtf|txt',

            help=re.sub("\s\s+" , " ", """A regular expression listing the file formats to archive. 
            This would commonly be a subset of the image formats listed here 
            as default, plus any custom range of document (or other file) formats. 
            Note that only supported image formats will be dhashed.""")),
        
    ):
    """Scan a given directory or list of directories for image files and
    documents. Store these files under ./data/ with filenames
    corresponding to sha1 hashes of the content. This removes
    duplicates.

    In addition, create a database of the files at ./data.json, which
    contains additional information about each image, such as format,
    size, and a difference hash, which can be used to identify similar
    images even if they are edited versions of each other, such as
    rescaled in size (small Hamming distance of the dhash indicates
    stronger similarity).

    """
    filetypes = re.compile(filetypes)
    _scan(directories, diskname, filetypes)
    
subapp = typer.Typer()
@subapp.callback()
def subapp_callback():
    "Provide various listings of the ./data.json database."
    pass

@subapp.command()
def disks():
    "List all known disks."
    entries = db.all()
    entries = [File(**dict(e)) for e in entries]
    disks = {e.diskname for e in entries}
    disks = [
        (d,
         sum(1 for e in entries if e.diskname == d),
         sum(1 for e in entries if (e.diskname == d) and (e.dhash128))
         )
        for d in sorted(tuple(disks))]
    print(tabulate(disks,headers = ['Disk name', 'Total entries', 'Images']))

def sizeof_fmt(num,fill=True):
    for unit in ['B','k','M','G','T','P','E','Z']:
        if abs(num) < 1024.0:
            s = '%.0f%s' % (num, unit)
            if fill:
                return f'{"_"*(5-len(s))}{s}'
            else:
                return s
            # return re.sub('0','_', '%04.0f%s' % (num, unit))
        num /= 1024.0
    return "%.0f%s" % (num, 'YB')

@subapp.command()
def files(
        disk_regex: str = typer.Option("", help="Restrict output to a particular disk names (given as case-insensitieve regex)."),
        file_regex: str = typer.Option("", help="Restrict output to a particular file names (given as case-insensitive regex)."),
        min_img_size: tuple[int,int] = typer.Option((0,0), help="Restrict output to image files of minimum dimension."),
        max_img_size: tuple[int,int] = typer.Option((0,0), help="Restrict output to image files of maximal dimension ((0,0) disables this)."),
        min_size: int = typer.Option(None, help="Restrict output to files of given minimal size (in bytes)."),
        max_size: int = typer.Option(None, help="Restrict output to files of given maximal size (in bytes)."),
        img_type_regex: str = typer.Option(None, help="Restrict output to image files of particular type (regex)."),
    ):
    "List files in database."
    entries = db.all()
    entries = [File(**dict(e)) for e in entries]

    if min_size:
        entries = [e for e in entries if e.size >= min_size]
    if max_size:
        entries = [e for e in entries if e.size <= max_size]
    if img_type_regex:
        entries = [e for e in entries if e.imgtype and re.match(img_type_regex,e.imgtype)]

    if sum(min_img_size) > 0:
        # file_list = [(path, disk, sha1, size, imgtype, imgsize)
        #              for (path, disk, sha1, size, imgtype, imgsize) in file_list
        #              if imgsize and (imgsize[0]>=min_img_size[0]) and (imgsize[1]>=min_img_size[1])]
        entries = [e for e in entries
                   if e.im_size and (e.im_size[0]>=min_img_size[0]) and (e.im_size[1]>=min_img_size[1])]
    if sum(max_img_size) > 0:
        # file_list = [(path, disk, sha1, size, imgtype, imgsize)
        #              for (path, disk, sha1, size, imgtype, imgsize) in file_list
        #              if imgsize and (imgsize[0]<=max_img_size[0]) and (imgsize[1]<=max_img_size[1])]
        entries = [e for e in entries
                   if e.im_size and (e.im_size[0]<=max_img_size[0]) and (e.im_size[1]<=max_img_size[1])]
    
    file_list = [
        (f'"{e.path}"',
         e.diskname,
         # f'/{e.sha1[:6]}',
         f'/{e.sha1[:2]}/{e.sha1[2:]}',
         sizeof_fmt(e.size),
         e.imgtype,
         e.im_size,
         )
        for e in entries if (re.search(disk_regex,e.diskname,re.I) and re.search(file_regex, e.path,re.I))]

        
    file_list.sort(key = lambda f: f[0])
    print(tabulate(file_list,headers = ['File', 'Disk', 'SHA1', 'Size', 'ImgType', 'ImgSize']))
    
    
app.add_typer(subapp, name='ls')
    
@app.command()
def stat():
    """
    Provide statistics about the ./data.json database.
    """
    entries = db.all()
    entries = [File(**dict(e)) for e in entries]
    sha1s = {e.sha1 for e in entries}
    stats = [
        ('Total db entries', len(entries)),
        ('Unique SHA1s', len(sha1s)),
        ('Image files (non-unique)', sum((1 for e in entries if e.imgtype))),
        ('Image files (unique)', len({e.sha1 for e in entries if e.imgtype})),
        ('Image dhash128 (unique)', len({e.dhash128 for e in entries if e.dhash128})),
        ('Combinded file sizes', sizeof_fmt(sum((e.size for e in entries)),fill=False)),
        ('Combinded image file sizes', sizeof_fmt(sum((e.size for e in entries if e.imgtype)),fill=False)),
        ('Total storage used', sizeof_fmt(sum(
            dict((e.sha1, e.size) for e in entries).values()
        ),fill=False)),
        ('Total storage used by images', sizeof_fmt(sum(
            dict((e.sha1, e.size) for e in entries if e.imgtype).values()
        ),fill=False)),
    ]
    print(tabulate(stats, headers=['Statistic','#']))
        
@app.callback()
def callback():
    """Scan directory trees and extract images (and other fileformats) and
    store them in a unified location, while preserving information
    about the source location. During this preservation stage, exact
    duplicates (same sha1 hash) are removed, even though information
    about all identical copies is preserved. In a secondary stage a
    perceptial difference hash for image file is used to identify
    images that appear to be the same, even though they may have
    different resolutions or have been edited for colour, sharpness,
    etc. These images are then clustered together.

    Copyright (C) 2021 by Björn Rüffer
    """
    pass
    

    
if __name__ == "__main__":
    app()


# Local Variables:
# mode: python
# pyvenv-workon: ~/Documents/Software/ardedup/venv
# End:
